{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2436, 2, 4)\n"
     ]
    }
   ],
   "source": [
    "############################################################################################################\n",
    "# Training neural networks using activation matrices and EMG peak-to-peak values\n",
    "############################################################################################################\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Select the stimulation side (L or R)\n",
    "side = 'L'\n",
    "\n",
    "path = '.\\\\Data\\\\Neural activity 20230217\\\\'+side+'\\\\a_matric\\\\scale_factor_1_100_20230216\\\\5.7'\n",
    "path_list = os.listdir(path)\n",
    "\n",
    "# Check whether all the files are availible\n",
    "pattern_range = []\n",
    "\n",
    "file_range = range(2437)\n",
    "for i in file_range:\n",
    "    filename = 'a_matric_'+str(i)+'.npy'\n",
    "    if filename in path_list:\n",
    "        pattern_range.append(i)\n",
    "\n",
    "# Load activation matrices\n",
    "a_16 = np.zeros([len(pattern_range),320])\n",
    "a_10 = np.zeros([len(pattern_range),320])\n",
    "a_73 = np.zeros([len(pattern_range),320])\n",
    "a_57 = np.zeros([len(pattern_range),320])\n",
    "\n",
    "k = 0\n",
    "for i in pattern_range:\n",
    "    a_16[k,:] = np.load('.\\\\Data\\\\Neural activity 20230217\\\\'+side+'\\\\a_matric\\\\scale_factor_1_100_20230216\\\\16.0\\\\a_matric_'+str(i)+'.npy')\n",
    "    a_10[k,:] = np.load('.\\\\Data\\\\Neural activity 20230217\\\\'+side+'\\\\a_matric\\\\scale_factor_1_100_20230216\\\\10.0\\\\a_matric_'+str(i)+'.npy')\n",
    "    a_73[k,:] = np.load('.\\\\Data\\\\Neural activity 20230217\\\\'+side+'\\\\a_matric\\\\scale_factor_1_100_20230216\\\\7.3\\\\a_matric_'+str(i)+'.npy')\n",
    "    a_57[k,:] = np.load('.\\\\Data\\\\Neural activity 20230217\\\\'+side+'\\\\a_matric\\\\scale_factor_1_100_20230216\\\\5.7\\\\a_matric_'+str(i)+'.npy')\n",
    "    k += 1\n",
    "    \n",
    "zip_16 = np.zeros((len(pattern_range),32))\n",
    "zip_10 = np.zeros((len(pattern_range),32))\n",
    "zip_73 = np.zeros((len(pattern_range),32))\n",
    "zip_57 = np.zeros((len(pattern_range),32))\n",
    "for i in range(len(pattern_range)):\n",
    "    for j in range(320):\n",
    "        zip_16[i,int(j/10)] += a_16[i,j]\n",
    "        zip_10[i,int(j/10)] += a_10[i,j]\n",
    "        zip_73[i,int(j/10)] += a_73[i,j]\n",
    "        zip_57[i,int(j/10)] += a_57[i,j]\n",
    "\n",
    "X_DC = loadmat(r'.\\\\Data\\\\x_column.mat')['x']\n",
    "x_dc = X_DC[:,0]\n",
    "sort_index = np.argsort(x_dc)\n",
    "R_index_dc = sort_index[0:int(sort_index.shape[0] / 2)]\n",
    "L_index_dc = sort_index[int(sort_index.shape[0] / 2):]\n",
    "\n",
    "D_list = [16.0,10.0,7.3,5.7]\n",
    "dc_a =np.zeros((len(pattern_range),2,4))\n",
    "n = 0\n",
    "for k in pattern_range:\n",
    "    for j in range(4):\n",
    "        a_m = np.load('.\\\\Data\\\\Neural activity 20230217\\\\'+side+'\\\\column_a_matric\\\\scale_factor_1_100_20230216\\\\'+str(D_list[j])+'\\\\ca_matric_'+str(k)+'.npy')\n",
    "        L_n = 0\n",
    "        R_n = 0\n",
    "        for i in range(a_m.shape[0]):\n",
    "            if (a_m[i]==1) and (i in L_index_dc):\n",
    "                L_n += 1\n",
    "            elif (a_m[i]==1) and (i in R_index_dc):\n",
    "                R_n += 1\n",
    "        L_ratio = L_n/L_index_dc.shape[0]\n",
    "        R_ratio = R_n/R_index_dc.shape[0]\n",
    "        dc_a[n,0,j] = L_ratio\n",
    "        dc_a[n,1,j] = R_ratio\n",
    "    n = n + 1\n",
    "\n",
    "print(dc_a.shape)\n",
    "x = np.zeros((len(pattern_range),16+2,4))\n",
    "x[:,0:16,0] = zip_16[:,0:16]/10\n",
    "x[:,0:16,1] = zip_10[:,0:16]/10\n",
    "x[:,0:16,2] = zip_73[:,0:16]/10\n",
    "x[:,0:16,3] = zip_57[:,0:16]/10\n",
    "x[:,16:18,:] = dc_a\n",
    "\n",
    "# Load EMG peak-to-peak values\n",
    "data_frame = pd.read_excel(r'.\\\\Data\\\\EMG data of P2\\\\P2_Mapping_20230217.xlsx',sheet_name=side,header=0,usecols=range(12))\n",
    "EMG = np.array(data_frame)\n",
    "\n",
    "# Nomarlization with the maximum of each channel\n",
    "m1 = [2476.925299,2713.996826,655.707048,2761.23056,5883.62704,469.9733753,661.5074164,2377.081812,950.7308385,1726.09589,1635.000931,961.7593543]\n",
    "m2 = [1582.94892,2481.605571,474.2016415,2529.903187,4396.750533,372.8770509,1524.564656,2915.445047,1343.855694,1847.565441,2173.126584,946.5696596]\n",
    "m = []\n",
    "for i in range(12):\n",
    "    if m1[i] > m2[i]:\n",
    "        m.append(m1[i])\n",
    "    else:\n",
    "        m.append(m2[i])\n",
    "\n",
    "EMG = EMG/m\n",
    "emg_range = []\n",
    "for i in range(len(pattern_range)):\n",
    "    emg_range.append(pattern_range[i]-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel 0: 0.1439083296516631\n",
      "Net(\n",
      "  (hidden1): Linear(in_features=4, out_features=18, bias=True)\n",
      "  (hidden2): Linear(in_features=324, out_features=6, bias=True)\n",
      "  (predict): Linear(in_features=6, out_features=1, bias=True)\n",
      ")\n",
      "0 0 End!\n",
      "test loss: tensor(0.0099, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "v_loss: tensor(0.0163, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "0 1 End!\n",
      "test loss: tensor(0.0099, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "v_loss: tensor(0.0158, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "0 2 End!\n",
      "test loss: tensor(0.0106, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "v_loss: tensor(0.0161, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Define loss function, containing Ordinal Loss and MSE Loss\n",
    "def lossfunc(x, y, predict, net):\n",
    "    \n",
    "    mse_loss = torch.nn.MSELoss()(y, predict)\n",
    "    \n",
    "    x_h = x.cpu().numpy()\n",
    "    x_l = x.cpu().numpy()\n",
    "    \n",
    "    index1 = list(np.random.randint(0,x.shape[0],size=int(0.1*x.shape[0])))\n",
    "    x_h = x_h[index1,:,:]\n",
    "    x_l = x_l[index1,:,:]\n",
    "    index2 = list(np.random.randint(0,18,size=np.random.randint(5,12)))\n",
    "    x_h[:,index2,:] = x_h[:,index2,:] + 0.1\n",
    "    x_l[:,index2,:] = x_l[:,index2,:] - 0.1\n",
    "    x_h = np.minimum(x_h, 1)\n",
    "    x_l = np.maximum(x_l, 0)\n",
    "\n",
    "    sort_loss = 0\n",
    "    mu = 1\n",
    "    \n",
    "    x_h = torch.from_numpy(x_h).cuda()\n",
    "    x_l = torch.from_numpy(x_l).cuda()\n",
    "    y_h = net(x_h)\n",
    "    y_l = net(x_l)\n",
    "    \n",
    "    dif_h = (predict[index1] - y_h).detach().cpu().numpy()\n",
    "    dif_l = (y_l - predict[index1]).detach().cpu().numpy()\n",
    "    dif_h = np.maximum(dif_h, 0)\n",
    "    dif_l = np.maximum(dif_l, 0)\n",
    "    sort_loss = np.mean(dif_h) + np.mean(dif_l)\n",
    "    \n",
    "    loss = mse_loss + sort_loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Define neural network\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.hidden1 = torch.nn.Linear(4,18)\n",
    "        self.hidden2 = torch.nn.Linear(18*18,6)\n",
    "        self.predict = torch.nn.Linear(6,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.hidden1(x))\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = torch.sigmoid(self.hidden2(x))\n",
    "        x = torch.sigmoid(self.predict(x))\n",
    "        x = torch.flatten(x)\n",
    "        return x\n",
    "\n",
    "# Training with 5-fold strategy: save a best model for each fold\n",
    "for channel in [0,1,2,3,4,5,6,7,8,9,10,11]:\n",
    "    y = EMG[emg_range,channel]\n",
    "\n",
    "    index_lose  = []\n",
    "    for i in range(y.shape[0]):\n",
    "        if y[i] < 0:\n",
    "            index_lose.append(i) \n",
    "\n",
    "    y = np.delete(y,index_lose)\n",
    "    x = np.delete(x,index_lose,axis=0)\n",
    "\n",
    "    # print(y.shape)\n",
    "    print('channel ' + str(channel) + ':',np.mean(y))\n",
    "\n",
    "    max_y = max(y)\n",
    "    y = y/max_y\n",
    "\n",
    "    x_tt, x_v, y_tt, y_v = train_test_split(x, y, test_size=0.2, random_state=14)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=14)\n",
    "\n",
    "    net = Net()\n",
    "    net = net.cuda()\n",
    "    print(net)\n",
    "\n",
    "    opt = torch.optim.SGD(net.parameters(),lr=0.5)\n",
    "\n",
    "    lossfunc2 = torch.nn.MSELoss()\n",
    "    lossfunc2 = lossfunc2.cuda()\n",
    "    \n",
    "    global_best_loss = 1\n",
    "    v_pred = []\n",
    "    for fold, (train_ids, test_ids) in enumerate(kf.split(x_tt)):\n",
    "        x_train = x_tt[train_ids,:,:]\n",
    "        y_train = y_tt[train_ids]\n",
    "        x_test = x_tt[test_ids,:,:]\n",
    "        y_test = y_tt[test_ids]\n",
    "    \n",
    "        x_train = torch.tensor(x_train)\n",
    "        y_train = torch.tensor(y_train)\n",
    "        x_test = torch.tensor(x_test)\n",
    "        y_test = torch.tensor(y_test)\n",
    "        x_v, y_v, x_tt, y_tt = torch.tensor(x_v),torch.tensor(y_v),torch.tensor(x_tt),torch.tensor(y_tt)\n",
    "\n",
    "        x_train = x_train.to(torch.float32)\n",
    "        y_train = y_train.to(torch.float32)\n",
    "        x_test = x_test.to(torch.float32)\n",
    "        y_test = y_test.to(torch.float32)\n",
    "        x_v, y_v, x_tt, y_tt = x_v.to(torch.float32),y_v.to(torch.float32),x_tt.to(torch.float32),y_tt.to(torch.float32)\n",
    "        \n",
    "        x_train,y_train = Variable(x_train),Variable(y_train)\n",
    "        x_test,y_test = Variable(x_test),Variable(y_test)\n",
    "        x_v, y_v, x_tt, y_tt = Variable(x_v),Variable(y_v),Variable(x_tt),Variable(y_tt)\n",
    "        \n",
    "        x_train = x_train.cuda()\n",
    "        y_train = y_train.cuda()\n",
    "        x_test = x_test.cuda()\n",
    "        y_test = y_test.cuda()\n",
    "        x_v, y_v, x_tt, y_tt = x_v.cuda(),y_v.cuda(),x_tt.cuda(),y_tt.cuda()\n",
    "###############################################################################################################################\n",
    "        global_best_loss = 100\n",
    "        min_test_loss = 100\n",
    "        for i in range(5):\n",
    "            net = Net()\n",
    "            net = net.cuda()\n",
    "            opt = torch.optim.SGD(net.parameters(),lr=0.5)\n",
    "            min_test_loss = 100\n",
    "            for t in range(30000):\n",
    "                prediction = net(x_train)\n",
    "                loss = lossfunc(x_train, y_train, prediction, net)\n",
    "                loss = loss.cuda()\n",
    "                test_prediction = net(x_test)\n",
    "                test_loss = lossfunc2(y_test, test_prediction)\n",
    "                if test_loss < min_test_loss:\n",
    "                    min_test_loss = test_loss\n",
    "                    torch.save(net, '.\\\\Data\\\\Torch models\\\\P2_20240716_'+side+'_channel'+str(channel)+'_fold'+str(fold)+'_round'+str(i)+'.pt')\n",
    "                if test_loss <= global_best_loss:\n",
    "                    global_best_loss = test_loss\n",
    "                    torch.save(net, '.\\\\Data\\\\Torch models\\\\P2_20240716_'+side+'_channel'+str(channel)+'_fold'+str(fold)+'_best.pt')\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            print(fold,i,\"End!\")\n",
    "            print(\"test loss:\",min_test_loss)\n",
    "            v_prediction = net(x_v)\n",
    "            v_pred.append(v_prediction)\n",
    "            v_loss = lossfunc2(v_prediction, y_v)\n",
    "            print(\"v_loss:\",v_loss)\n",
    "        temp_model = torch.load(r'.\\\\Data\\\\Torch models\\\\P2_20240716_'+side+'_channel'+str(channel)+'_fold'+str(fold)+'_best.pt')\n",
    "#         temp_model = temp_model.cpu()\n",
    "        v_prediction = temp_model(x_v)\n",
    "        v_pred.append(v_prediction)\n",
    "        v_loss = lossfunc2(v_prediction, y_v)\n",
    "    mean_vp = (v_pred[0]+v_pred[1]+v_pred[2]+v_pred[3]+v_pred[4])/5\n",
    "    mean_vloss = lossfunc2(mean_vp, y_v)\n",
    "    print(\"mean_vloss:\", mean_vloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
